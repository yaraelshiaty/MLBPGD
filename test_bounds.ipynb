{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import torch_scatter\n",
    "\n",
    "import MGBlurr.blurring as blur\n",
    "from MGTomo import gridop\n",
    "from MGTomo.gridop import RBox as R, PBox as P\n",
    "from skimage import data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthant_bounds(xh, xH, P_inf, lh, P_nonzero = None):\n",
    "    if P_nonzero is None:\n",
    "        coarse_dim = xH.shape[0]\n",
    "        P_nonzero = gridop.compute_nonzero_elements_of_P(coarse_dim)\n",
    "    \n",
    "    lH = torch.zeros_like(xH)\n",
    "\n",
    "    for col_coord, indices in P_nonzero.items():\n",
    "        rows, cols = zip(*indices)\n",
    "        \n",
    "        rows = torch.tensor(rows)\n",
    "        cols = torch.tensor(cols)\n",
    "        \n",
    "        diffs = xh[rows, cols]\n",
    "        lmax = torch.max(lh[rows, cols] - diffs)\n",
    "        \n",
    "        lH[col_coord] = xH[col_coord] + lmax / P_inf\n",
    "    return lH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthant_bounds_optimized(xh, xH, P_inf, lh, P_nonzero=None):\n",
    "    coarse_dim = xH.shape[0]\n",
    "\n",
    "    if P_nonzero is None:\n",
    "        P_nonzero = gridop.compute_nonzero_elements_of_P(coarse_dim)\n",
    "    \n",
    "    lH = torch.zeros_like(xH)\n",
    "\n",
    "    all_rows = []\n",
    "    all_cols = []\n",
    "    col_coords_flat = []\n",
    "    col_coords = []\n",
    "\n",
    "    for (x,y), indices in P_nonzero.items():\n",
    "        rows, cols = zip(*indices)\n",
    "        all_rows.extend(rows)\n",
    "        all_cols.extend(cols)\n",
    "        col_coords_flat.extend([x*coarse_dim + y]*len(rows))\n",
    "        col_coords.append((x,y))\n",
    "\n",
    "    all_rows_tensor = torch.tensor(all_rows)\n",
    "    all_cols_tensor = torch.tensor(all_cols)\n",
    "    all_col_coords = torch.tensor(col_coords_flat)\n",
    "\n",
    "    rowsH_tensor, colsH_tensor = torch.tensor(col_coords).unbind(dim=1)\n",
    "\n",
    "    diffs = xh[all_rows_tensor, all_cols_tensor]\n",
    "  \n",
    "    lmax = torch_scatter.scatter_max(lh[all_rows_tensor, all_cols_tensor] - diffs, all_col_coords, dim = 0)[0]\n",
    "    lH[rowsH_tensor, colsH_tensor] = xH[rowsH_tensor, colsH_tensor] + lmax / P_inf\n",
    "\n",
    "    return lH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_bounds_optimized(xh, xH, P_inf, lh, uh, P_nonzero=None):\n",
    "    if P_nonzero is None:\n",
    "        coarse_dim = xH.shape[0]\n",
    "        P_nonzero = gridop.compute_nonzero_elements_of_P(coarse_dim)\n",
    "    \n",
    "    lH = torch.zeros_like(xH)\n",
    "    uH = torch.zeros_like(xH)\n",
    "    coarse_dim = xH.shape[0]\n",
    "\n",
    "    # Collect all the rows and columns indices in one go\n",
    "    all_rows = []\n",
    "    all_cols = []\n",
    "    col_coords_flat = []\n",
    "    col_coords = []\n",
    "\n",
    "    for (x,y), indices in P_nonzero.items():\n",
    "        rows, cols = zip(*indices)\n",
    "        all_rows.extend(rows)\n",
    "        all_cols.extend(cols)\n",
    "        col_coords_flat.extend([x*coarse_dim + y]*len(rows))\n",
    "        col_coords.append((x,y))\n",
    "\n",
    "    # Convert to tensors once\n",
    "    all_rows_tensor = torch.tensor(all_rows)\n",
    "    all_cols_tensor = torch.tensor(all_cols)\n",
    "    all_col_coords = torch.tensor(col_coords_flat)\n",
    "\n",
    "    rowsH, colsH = zip(*col_coords)\n",
    "    rowsH_tensor = torch.tensor(rowsH)\n",
    "    colsH_tensor = torch.tensor(colsH)\n",
    "\n",
    "    # Calculate diffs in one go\n",
    "    diffs = xh[all_rows_tensor, all_cols_tensor]\n",
    "  \n",
    "    lmax = torch_scatter.scatter_max(lh[all_rows_tensor, all_cols_tensor] - diffs, all_col_coords, dim = 0)[0]\n",
    "    umin = torch_scatter.scatter_min(uh[all_rows_tensor, all_cols_tensor] - diffs, all_col_coords, dim = 0)[0]\n",
    "    lH[rowsH_tensor, colsH_tensor] = xH[rowsH_tensor, colsH_tensor] + lmax / P_inf\n",
    "    uH[rowsH_tensor, colsH_tensor] = xH[rowsH_tensor, colsH_tensor] + umin / P_inf\n",
    "\n",
    "    return lH, uH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1023\n",
    "max_levels = 1\n",
    "maxIter = [1,2,16,32,64,128]\n",
    "kernel_size = 33\n",
    "sigma = 10\n",
    "\n",
    "# load image\n",
    "x_orig = data.camera()\n",
    "x_orig = resize(x_orig, (N,N), anti_aliasing = False)\n",
    "\n",
    "x_torch = torch.tensor(x_orig, requires_grad = True)\n",
    "\n",
    "A = [blur.GaussianBlurOperator(N, kernel_size, sigma)]\n",
    "b = [torch.poisson(A[0](x_torch)*50)/50]\n",
    "P_nonzero = []\n",
    "\n",
    "fine_dim = N\n",
    "for i in range(1, max_levels+1):\n",
    "    coarse_dim = blur.reduce_dim(fine_dim)\n",
    "    A.append(blur.GaussianBlurOperator(coarse_dim, kernel_size, sigma))\n",
    "    rhs = resize(b[-1].detach().numpy(), (coarse_dim, coarse_dim), anti_aliasing=False)\n",
    "    b.append(torch.tensor(rhs, requires_grad=True)) #maybe use a different way to define bH\n",
    "    P_nonzero.append(gridop.compute_nonzero_elements_of_P(coarse_dim))\n",
    "    fine_dim = coarse_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xh = torch.rand(1023,1023)\n",
    "xH = gridop.R(xh)\n",
    "\n",
    "\n",
    "lh = torch.zeros_like(xh)\n",
    "uh = torch.ones_like(xh)\n",
    "\n",
    "P_inf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.1860,  8.9615,  7.3578,  ..., 10.7755,  8.3521,  8.8985],\n",
       "        [ 9.9855,  8.3821,  9.0785,  ...,  9.4574,  5.6935,  5.3180],\n",
       "        [ 5.7296,  7.3632,  9.4823,  ...,  5.2250,  3.7747,  7.3206],\n",
       "        ...,\n",
       "        [ 8.4354,  8.1098,  9.9939,  ...,  7.0442,  6.2207,  9.9500],\n",
       "        [ 8.3429,  9.8839, 10.8665,  ...,  9.8678, 10.8622,  9.0042],\n",
       "        [ 7.1527, 10.2624,  7.0788,  ...,  7.8803,  8.1784,  5.1626]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthant_bounds(xh, xH, 1, lh, P_nonzero[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10.1860,  8.9615,  7.3578,  ..., 10.7755,  8.3521,  8.8985],\n",
       "        [ 9.9855,  8.3821,  9.0785,  ...,  9.4574,  5.6935,  5.3180],\n",
       "        [ 5.7296,  7.3632,  9.4823,  ...,  5.2250,  3.7747,  7.3206],\n",
       "        ...,\n",
       "        [ 8.4354,  8.1098,  9.9939,  ...,  7.0442,  6.2207,  9.9500],\n",
       "        [ 8.3429,  9.8839, 10.8665,  ...,  9.8678, 10.8622,  9.0042],\n",
       "        [ 7.1527, 10.2624,  7.0788,  ...,  7.8803,  8.1784,  5.1626]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthant_bounds_optimized(xh, xH, 1, lh, P_nonzero[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1023\u001b[39m,\u001b[38;5;241m1023\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 2\u001b[0m xH \u001b[38;5;241m=\u001b[39m \u001b[43mgridop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m lh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(xh, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m uh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(xh, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/multigrid/MGTomo/gridop.py:28\u001b[0m, in \u001b[0;36mR\u001b[0;34m(input_image)\u001b[0m\n\u001b[1;32m     25\u001b[0m kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Apply transposed convolution with bilinear interpolation kernel\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m output_image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_image\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "xh = torch.rand(1023,1023, device=device)\n",
    "xH = gridop.R(xh)\n",
    "\n",
    "\n",
    "lh = torch.zeros_like(xh, device=device)\n",
    "uh = torch.ones_like(xh, device=device)\n",
    "\n",
    "P_inf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter  # Ensure you have torch_scatter installed\n",
    "\n",
    "def orthant_bounds_optimized(xh, xH, P_inf, lh, P_nonzero=None):\n",
    "    if P_nonzero is None:\n",
    "        coarse_dim = xH.shape[0]\n",
    "        P_nonzero = gridop.compute_nonzero_elements_of_P(coarse_dim)\n",
    "    \n",
    "    lH = torch.zeros_like(xH)\n",
    "\n",
    "    # Flatten indices from P_nonzero\n",
    "    all_rows = []\n",
    "    all_cols = []\n",
    "    col_coord_list = []\n",
    "\n",
    "    for col_coord, indices in P_nonzero.items():\n",
    "        rows, cols = zip(*indices)\n",
    "        all_rows.append(torch.tensor(rows, device=xh.device))  # Ensure device consistency\n",
    "        all_cols.append(torch.tensor(cols, device=xh.device))  # Ensure device consistency\n",
    "        col_coord_list.append(col_coord)\n",
    "\n",
    "    all_rows = torch.cat(all_rows)\n",
    "    all_cols = torch.cat(all_cols)\n",
    "\n",
    "    # Compute diffs in one go\n",
    "    diffs = xh[all_rows, all_cols]\n",
    "    lh_selected = lh[all_rows, all_cols]\n",
    "\n",
    "    # Calculate lmax across all selected rows and columns\n",
    "    lmax_per_col = torch_scatter.scatter_max(lh_selected - diffs, torch.tensor(col_coord_list, device=xh.device), dim=0)[0]\n",
    "\n",
    "    # Initialize lmax_per_col with -inf to handle any cases where col_coord might be missing\n",
    "    final_lmax_per_col = torch.full((xH.shape[0],), float('-inf'), device=xh.device)  # Change here\n",
    "\n",
    "    # Place the lmax_per_col values back into final_lmax_per_col\n",
    "    final_lmax_per_col.scatter_(0, torch.tensor(col_coord_list, device=xh.device), lmax_per_col)\n",
    "\n",
    "    # Update lH in one go\n",
    "    lH[torch.tensor(col_coord_list, device=xh.device)] = xH[torch.tensor(col_coord_list, device=xh.device)] + final_lmax_per_col / P_inf\n",
    "    \n",
    "    return lH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthant_bounds(xh, xH, 1, lh, P_nonzero[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
