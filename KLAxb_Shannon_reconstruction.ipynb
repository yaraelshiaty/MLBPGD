{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0: 200 1023.0\n",
      "level 1: 100 511.0\n",
      "level 2: 100 255.0\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 0: 7427490.200336085 - Time: 30.567667 seconds\n",
      "tensor(239182.2500, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(23719.2285, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 1: 3799077.389332043 - Time: 30.256962 seconds\n",
      "tensor(2800.0151, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(61.1547, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 2: 2058670.2134430325 - Time: 30.417014 seconds\n",
      "tensor(1538.0952, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(37.3569, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 3: 1224709.2592820497 - Time: 30.350555 seconds\n",
      "tensor(829.0059, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(27.6955, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 4: 812946.0525858547 - Time: 30.375039 seconds\n",
      "tensor(452.6335, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(22.1971, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 5: 595604.570959889 - Time: 30.890193 seconds\n",
      "tensor(258.7903, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(18.0622, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 6: 469463.98047660466 - Time: 30.386709 seconds\n",
      "tensor(158.4600, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(14.6575, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 7: 388431.7365119773 - Time: 30.094689 seconds\n",
      "tensor(104.4262, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(11.8683, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 8: 331619.9044524753 - Time: 30.199502 seconds\n",
      "tensor(73.4037, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(9.6303, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 9: 289117.5118840023 - Time: 30.304759 seconds\n",
      "tensor(54.2605, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(7.8621, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 10: 255862.17443278144 - Time: 31.065918 seconds\n",
      "tensor(41.6422, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(6.4729, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 11: 229027.94277453696 - Time: 30.365106 seconds\n",
      "tensor(32.8687, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(5.3795, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 12: 206893.08578975435 - Time: 30.605250 seconds\n",
      "tensor(26.5136, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(4.5143, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 13: 188327.2247147355 - Time: 30.337892 seconds\n",
      "tensor(21.7652, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(3.8243, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 14: 172545.05077345026 - Time: 30.482739 seconds\n",
      "tensor(18.1306, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(3.2689, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 15: 158977.9793743749 - Time: 30.434335 seconds\n",
      "tensor(15.2934, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(2.8175, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 16: 147202.0701594157 - Time: 30.704089 seconds\n",
      "tensor(13.0417, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(2.4474, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 17: 136893.9302143541 - Time: 30.510142 seconds\n",
      "tensor(11.2292, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(2.1412, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 18: 127802.30816902342 - Time: 30.269964 seconds\n",
      "tensor(9.7519, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.8857, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 19: 119729.1376034026 - Time: 30.268085 seconds\n",
      "tensor(8.5345, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.6707, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 20: 112516.37253904587 - Time: 30.020942 seconds\n",
      "tensor(7.5213, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.4887, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 21: 106036.45111100604 - Time: 30.383257 seconds\n",
      "tensor(6.6704, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.3332, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 22: 100185.44672438168 - Time: 30.539427 seconds\n",
      "tensor(5.9499, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.1998, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 23: 94877.84616492665 - Time: 30.225643 seconds\n",
      "tensor(5.3352, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(1.0844, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 24: 90042.78101265318 - Time: 30.131810 seconds\n",
      "tensor(4.8072, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.9842, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 25: 85621.00426106271 - Time: 30.137054 seconds\n",
      "tensor(4.3508, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.8967, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 26: 81562.59767107331 - Time: 30.516298 seconds\n",
      "tensor(3.9539, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.8198, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 27: 77825.33973736312 - Time: 30.255891 seconds\n",
      "tensor(3.6070, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.7521, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 28: 74373.1966051373 - Time: 30.324780 seconds\n",
      "tensor(3.3022, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.6920, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 29: 71175.29272721884 - Time: 30.362911 seconds\n",
      "tensor(3.0331, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.6386, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 30: 68205.01232096706 - Time: 30.413041 seconds\n",
      "tensor(2.7944, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.5909, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 31: 65439.346409285645 - Time: 30.091214 seconds\n",
      "tensor(2.5819, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.5481, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 32: 62858.27507143622 - Time: 30.740577 seconds\n",
      "tensor(2.3918, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.5096, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 33: 60444.260737850054 - Time: 30.390960 seconds\n",
      "tensor(2.2213, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.4749, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 34: 58181.960794538514 - Time: 30.094652 seconds\n",
      "tensor(2.0677, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.4434, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 35: 56057.823151108736 - Time: 30.278453 seconds\n",
      "tensor(1.9289, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.4148, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 36: 54059.87166677276 - Time: 30.205060 seconds\n",
      "tensor(1.8031, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.3888, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 37: 52177.47882264258 - Time: 30.678143 seconds\n",
      "tensor(1.6887, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.3650, requires_grad=True)\n",
      "1  : coarse correction activated\n",
      "Iteration 38: 50401.19845307456 - Time: 30.700430 seconds\n",
      "tensor(1.5843, requires_grad=True)\n",
      "0  : coarse correction activated\n",
      "tensor(0.3432, requires_grad=True)\n",
      "1  : coarse correction activated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mML_iterate_count\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    153\u001b[0m     iteration_start_time_ML \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 155\u001b[0m     val, ylast \u001b[38;5;241m=\u001b[39m MLO_box(fh, z0, lh, uh, last_pts)\n\u001b[1;32m    156\u001b[0m     iteration_end_time_ML \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    157\u001b[0m     iteration_time_ML \u001b[38;5;241m=\u001b[39m iteration_end_time_ML \u001b[38;5;241m-\u001b[39m iteration_start_time_ML\n",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m, in \u001b[0;36mMLO_box\u001b[0;34m(fh, y, lh, uh, last_pts, l, kappa, eps)\u001b[0m\n\u001b[1;32m    105\u001b[0m     x\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m<\u001b[39m hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_levels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     x, last_pts \u001b[38;5;241m=\u001b[39m MLO_box(psi, x,lH, uH, last_pts, l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    110\u001b[0m d \u001b[38;5;241m=\u001b[39m P(x\u001b[38;5;241m-\u001b[39mx0)\n\u001b[1;32m    111\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m armijo_linesearch(fh, y, d)\n",
      "Cell \u001b[0;32mIn[1], line 120\u001b[0m, in \u001b[0;36mMLO_box\u001b[0;34m(fh, y, lh, uh, last_pts, l, kappa, eps)\u001b[0m\n\u001b[1;32m    116\u001b[0m logvh_new \u001b[38;5;241m=\u001b[39m mylog(y \u001b[38;5;241m-\u001b[39m lh) \u001b[38;5;241m-\u001b[39m mylog(uh \u001b[38;5;241m-\u001b[39m y)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxIter\u001b[39m\u001b[38;5;124m\"\u001b[39m][l]):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#y.retain_grad()\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     yval, logvh_new \u001b[38;5;241m=\u001b[39m fcts\u001b[38;5;241m.\u001b[39mBSMART_general(fh, y, logvh_new, tau[l], lh, uh)\n\u001b[1;32m    121\u001b[0m     y \u001b[38;5;241m=\u001b[39m yval\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m yval\n",
      "File \u001b[0;32m~/multigrid/MGTomo/functions.py:98\u001b[0m, in \u001b[0;36mBSMART_general\u001b[0;34m(f, x, logv, tau, l, u)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(x_new \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m u \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-7\u001b[39m), torch\u001b[38;5;241m.\u001b[39msum(x_new \u001b[38;5;241m-\u001b[39m u \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m#(u - x_new).min()\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m#assert torch.all(x_new <= u), x_new.flatten()[(u - x_new).argmin()]\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (f(x_new) \u001b[38;5;241m-\u001b[39m fx)\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, logv\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_new, logv_new\n",
      "Cell \u001b[0;32mIn[1], line 96\u001b[0m, in \u001b[0;36mMLO_box.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m grad_fHx0\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 96\u001b[0m     psi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: fH(x) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(kappa \u001b[38;5;241m*\u001b[39m x)\n\u001b[1;32m     97\u001b[0m     lH, uH \u001b[38;5;241m=\u001b[39m box_bounds_optimized(y, x, hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m], lh, uh, P_nonzero[l])\n\u001b[1;32m     99\u001b[0m logvH_new \u001b[38;5;241m=\u001b[39m mylog(x \u001b[38;5;241m-\u001b[39m lH) \u001b[38;5;241m-\u001b[39m mylog(uH \u001b[38;5;241m-\u001b[39m x)\n",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m, in \u001b[0;36mMLO_box.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     83\u001b[0m last_pts[l] \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     85\u001b[0m x0 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 86\u001b[0m fH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: fcts\u001b[38;5;241m.\u001b[39mkl_distance(x, A[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], b[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \n\u001b[1;32m     87\u001b[0m fHx0 \u001b[38;5;241m=\u001b[39m fH(x0)\n\u001b[1;32m     88\u001b[0m fHx0\u001b[38;5;241m.\u001b[39mbackward(retain_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/multigrid/MGTomo/functions.py:8\u001b[0m, in \u001b[0;36mkl_distance\u001b[0;34m(x, proj, b)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl_distance\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mtensor, proj: mgproj\u001b[38;5;241m.\u001b[39mTomoTorch, b: torch\u001b[38;5;241m.\u001b[39mtensor):\n\u001b[0;32m----> 8\u001b[0m     ax \u001b[38;5;241m=\u001b[39m proj(x)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#ab = torch.divide(ax, b)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     ab \u001b[38;5;241m=\u001b[39m mydiv(ax,b)\n",
      "File \u001b[0;32m~/.conda/envs/MLcupy_v2/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/MLcupy_v2/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/multigrid/MGTomo/tomoprojection.py:36\u001b[0m, in \u001b[0;36mTomoTorch.forward\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AstraLinearFunction\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtomop, v)\n",
      "File \u001b[0;32m~/.conda/envs/MLcupy_v2/lib/python3.11/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m~/multigrid/MGTomo/tomoprojection.py:12\u001b[0m, in \u001b[0;36mAstraLinearFunction.forward\u001b[0;34m(ctx, tomo_matrix, input_vector)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, tomo_matrix, input_vector):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Perform the sparse matrix-vector multiplication\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m tomo_matrix\u001b[38;5;241m.\u001b[39mmatvec(input_vector\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     13\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64(output)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Save the custom sparse matrix and input vector for backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/multigrid/MGTomo/tomoprojection.py:75\u001b[0m, in \u001b[0;36mTomoParallel.matvec\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatvec\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[0;32m---> 75\u001b[0m   sid, s \u001b[38;5;241m=\u001b[39m astra\u001b[38;5;241m.\u001b[39mcreate_sino(v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_id) \u001b[38;5;66;03m# np.reshape(v, (vol_geom['GridRowCount'], vol_geom['GridColCount']))\u001b[39;00m\n\u001b[1;32m     76\u001b[0m   astra\u001b[38;5;241m.\u001b[39mdata2d\u001b[38;5;241m.\u001b[39mdelete(sid)\n\u001b[1;32m     77\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/.conda/envs/MLcupy_v2/lib/python3.11/site-packages/astra/creators.py:404\u001b[0m, in \u001b[0;36mcreate_sino\u001b[0;34m(data, proj_id, returnData, gpuIndex)\u001b[0m\n\u001b[1;32m    402\u001b[0m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolumeDataId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m volume_id\n\u001b[1;32m    403\u001b[0m alg_id \u001b[38;5;241m=\u001b[39m algorithm\u001b[38;5;241m.\u001b[39mcreate(cfg)\n\u001b[0;32m--> 404\u001b[0m algorithm\u001b[38;5;241m.\u001b[39mrun(alg_id)\n\u001b[1;32m    405\u001b[0m algorithm\u001b[38;5;241m.\u001b[39mdelete(alg_id)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/.conda/envs/MLcupy_v2/lib/python3.11/site-packages/astra/algorithm.py:47\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(i, iterations)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(i, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run an algorithm.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    :param i: ID of object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mrun(i,iterations)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import MGTomo.model as mgmodel\n",
    "import MGTomo.tomoprojection as mgproj\n",
    "from MGTomo.utils import mylog\n",
    "import MGTomo.functions as fcts\n",
    "from MGTomo.optimize import armijo_linesearch, box_bounds_optimized\n",
    "import MGTomo.coarse_corrections as CC\n",
    "from MGTomo.gridop import RBox as R, PBox as P\n",
    "\n",
    "from MGTomo import gridop\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.linalg import norm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    \"image\": \"shepp_logan\",\n",
    "    \"CC\": \"Bregman\",\n",
    "    \"N\": 1023,\n",
    "    \"max_levels\": 2,\n",
    "    \"maxIter\": [1,10,10,16,32,128],\n",
    "    \"num_angels0\": 200,\n",
    "    \"P_inf\" : 1,\n",
    "    #\"SL_iterate_count\": 0,\n",
    "    \"ML_iterate_count\": 120,\n",
    "    \"kappa\": 0.49,\n",
    "    \"eps\": 0.1,\n",
    "    #\"SL_image_indices\": range(0,0,0),\n",
    "    \"ML_image_indices\": range(0,10),\n",
    "    'remark': 'testing different eps'\n",
    "}\n",
    "\n",
    "x_orig = data.shepp_logan_phantom()\n",
    "x_orig = resize(x_orig, (hparams[\"N\"],hparams[\"N\"]), anti_aliasing = False)\n",
    "\n",
    "x_torch = torch.tensor(x_orig, requires_grad = True)\n",
    "\n",
    "\n",
    "model = mgmodel.astra_model(hparams[\"N\"],{'mode' : 'line', 'num_angles' : hparams[\"num_angels0\"], 'level_decrease' : 1})\n",
    "fine_dim = model.dim\n",
    "A = [mgproj.TomoTorch(model.proj_factory(fine_dim))]\n",
    "b = [A[0](x_torch)]\n",
    "level = {int(np.sqrt(A[0].shape[1])): 0}\n",
    "P_nonzero = []\n",
    "\n",
    "\n",
    "for i in range(1,hparams[\"max_levels\"]+1):\n",
    "    coarse_dim = model.reduce_dim(fine_dim)\n",
    "    model_coarse = mgmodel.astra_model(coarse_dim, {'mode' : 'line', 'num_angles' : min(int(coarse_dim*np.pi/4),100), 'level_decrease' : 1})\n",
    "    A.append(mgproj.TomoTorch(model_coarse.proj_factory(coarse_dim)))\n",
    "    x_resized = resize(x_orig, (coarse_dim, coarse_dim), anti_aliasing=False)\n",
    "    xT_resized = torch.tensor(x_resized, requires_grad = True)\n",
    "    b.append(A[-1](xT_resized))\n",
    "    P_nonzero.append(gridop.compute_nonzero_elements_of_P(coarse_dim))\n",
    "    level.update({int(np.sqrt(A[i].shape[1])): i})\n",
    "    fine_dim=coarse_dim\n",
    "\n",
    "for i in range(hparams[\"max_levels\"]+1):\n",
    "    assert b[i].shape[0]*b[i].shape[1] == A[i].shape[0], 'dimension mismatch'\n",
    "    print(f'level {i}:', b[i].shape[0], np.sqrt(A[i].shape[1]))\n",
    "\n",
    "fh = lambda x: fcts.kl_distance(x, A[0], b[0])\n",
    "tau = [torch.reciprocal(Ai.sumnorm_opt()) * 0.5 for Ai in A]\n",
    "\n",
    "def MLO_box(fh, y, lh, uh, last_pts: list, l=0, kappa = hparams[\"kappa\"], eps = hparams[\"eps\"]):\n",
    "    x = R(y).detach().requires_grad_(True)\n",
    "    fhy0 = fh(y)\n",
    "    #fhy0.backward(retain_graph = True)\n",
    "    fhy0.backward()\n",
    "    grad_fhy0 = y.grad.clone()\n",
    "    y.grad = None\n",
    "    \n",
    "    if CC.coarse_condition_bregman(y, grad_fhy0, kappa, eps, last_pts[l]):\n",
    "    #if True:\n",
    "        print(l, ' : coarse correction activated')\n",
    "        last_pts[l] = y.clone().detach()\n",
    "    \n",
    "        x0 = x.clone().detach().requires_grad_(True)\n",
    "        fH = lambda x: fcts.kl_distance(x, A[l+1], b[l+1]) \n",
    "        fHx0 = fH(x0)\n",
    "        fHx0.backward(retain_graph = True)\n",
    "        grad_fHx0 = x0.grad.clone()\n",
    "        x0.grad = None\n",
    "\n",
    "        kappa = R(grad_fhy0) - grad_fHx0\n",
    "        del grad_fHx0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            psi = lambda x: fH(x) + torch.sum(kappa * x)\n",
    "            lH, uH = box_bounds_optimized(y, x, hparams[\"P_inf\"], lh, uh, P_nonzero[l])\n",
    "\n",
    "        logvH_new = mylog(x - lH) - mylog(uH - x)\n",
    "        for i in range(hparams[\"maxIter\"][l+1]):\n",
    "            #x.retain_grad()\n",
    "            val, logvH_new = fcts.BSMART_general(psi, x, logvH_new, tau[l+1], lH, uH)\n",
    "            x = val.detach().requires_grad_(True)\n",
    "            del val\n",
    "            x.grad = None\n",
    "            \n",
    "        if l < hparams[\"max_levels\"]-1:\n",
    "            x, last_pts = MLO_box(psi, x,lH, uH, last_pts, l+1)\n",
    "\n",
    "        d = P(x-x0)\n",
    "        z, _ = armijo_linesearch(fh, y, d)\n",
    "        y = z.detach().requires_grad_(True)\n",
    "    else: \n",
    "        print(l, ' : coarse correction not activated')\n",
    "\n",
    "    logvh_new = mylog(y - lh) - mylog(uh - y)\n",
    "    \n",
    "    for i in range(hparams[\"maxIter\"][l]):\n",
    "        #y.retain_grad()\n",
    "        yval, logvh_new = fcts.BSMART_general(fh, y, logvh_new, tau[l], lh, uh)\n",
    "        y = yval.detach().requires_grad_(True)\n",
    "        del yval\n",
    "        y.grad = None\n",
    "    return y, last_pts\n",
    "\n",
    "\n",
    "z0 = torch.ones(hparams[\"N\"], hparams[\"N\"]) * 0.5\n",
    "z0.requires_grad_(True)\n",
    "last_pts = [None]*(hparams[\"max_levels\"]+1)\n",
    "\n",
    "lh = torch.zeros_like(z0)\n",
    "uh = torch.ones_like(z0)\n",
    "\n",
    "rel_f_err = []\n",
    "rel_f_err.append((norm(z0 - x_torch, 'fro')/norm(z0, 'fro')).item())\n",
    "\n",
    "norm_fval = []\n",
    "norm_fval.append(torch.tensor(1.))\n",
    "\n",
    "fhz = fh(z0)\n",
    "\n",
    "fhz.backward(retain_graph=True)\n",
    "Gz0 = norm(z0.grad, 'fro')\n",
    "z0.grad = None\n",
    "\n",
    "norm_grad = []\n",
    "norm_grad.append(torch.tensor(1.))\n",
    "\n",
    "iteration_times_ML = []\n",
    "iteration_times_ML.append(0)\n",
    "\n",
    "for i in range(hparams['ML_iterate_count']):\n",
    "    iteration_start_time_ML = time.time()\n",
    "    \n",
    "    val, ylast = MLO_box(fh, z0, lh, uh, last_pts)\n",
    "    iteration_end_time_ML = time.time()\n",
    "    iteration_time_ML = iteration_end_time_ML - iteration_start_time_ML\n",
    "\n",
    "    iteration_times_ML.append(iteration_time_ML)\n",
    "    z0 = val.clone().detach().requires_grad_(True)\n",
    "    rel_f_err.append((norm(z0-x_torch, 'fro')/norm(z0, 'fro')).item())\n",
    "    fval = fh(z0)\n",
    "    norm_fval.append((fval/fhz).item())\n",
    "    fval.backward(retain_graph=True)\n",
    "    norm_grad.append((norm(z0.grad, 'fro')/Gz0).item())\n",
    "    z0.grad = None\n",
    "\n",
    "    print(f\"Iteration {i}: {fh(z0)} - Time: {iteration_time_ML:.6f} seconds\")\n",
    "\n",
    "print(f\"Overall time for all iterations: {sum(iteration_times_ML):.6f} seconds\")\n",
    "cumaltive_times_ML = [sum(iteration_times_ML[:i+1]) for i in range(len(iteration_times_ML))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40: 27196.51908176774 - Time: 30.538825 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 41: 26573.063465931365 - Time: 30.528802 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 42: 25972.213658156772 - Time: 30.647747 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 43: 25392.84823452975 - Time: 30.466639 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 44: 24833.919101396372 - Time: 30.430084 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 45: 24294.447865086673 - Time: 30.463020 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 46: 23773.516898911603 - Time: 30.263099 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 47: 23270.258159563375 - Time: 31.127694 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 48: 22783.845990075555 - Time: 30.939758 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 49: 22313.531317739413 - Time: 30.512459 seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(40,50):\n",
    "    iteration_start_time_ML = time.time()\n",
    "    \n",
    "    val, ylast = MLO_box(fh, z0, lh, uh, last_pts)\n",
    "    iteration_end_time_ML = time.time()\n",
    "    iteration_time_ML = iteration_end_time_ML - iteration_start_time_ML\n",
    "\n",
    "    iteration_times_ML.append(iteration_time_ML)\n",
    "    z0 = val.clone().detach().requires_grad_(True)\n",
    "    rel_f_err.append((norm(z0-x_torch, 'fro')/norm(z0, 'fro')).item())\n",
    "    fval = fh(z0)\n",
    "    norm_fval.append((fval/fhz).item())\n",
    "    fval.backward(retain_graph=True)\n",
    "    norm_grad.append((norm(z0.grad, 'fro')/Gz0).item())\n",
    "    z0.grad = None\n",
    "\n",
    "    print(f\"Iteration {i}: {fh(z0)} - Time: {iteration_time_ML:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 60: 21858.58799242591 - Time: 30.717260 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 61: 21418.32727738731 - Time: 30.748801 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 62: 20992.10570035365 - Time: 30.651742 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 63: 20579.32037413214 - Time: 30.415018 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 64: 20179.38972685728 - Time: 30.452938 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 65: 19791.773311998968 - Time: 30.488975 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 66: 19415.9425740786 - Time: 30.243572 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 67: 19051.422692879587 - Time: 30.465314 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 68: 18697.746682478974 - Time: 30.461708 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 69: 18354.47278126115 - Time: 30.344467 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 70: 18021.187494347338 - Time: 30.411186 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 71: 17697.490583805444 - Time: 30.448533 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 72: 17383.008952280074 - Time: 30.310821 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 73: 17077.389818589192 - Time: 30.200284 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 74: 16780.284088411263 - Time: 30.491327 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 75: 16491.376513477022 - Time: 30.442463 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 76: 16210.356458060658 - Time: 30.760356 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 77: 15936.917094047114 - Time: 30.937745 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 78: 15670.79218818862 - Time: 30.774425 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 79: 15411.711362819524 - Time: 30.741267 seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(60,80):\n",
    "    iteration_start_time_ML = time.time()\n",
    "    \n",
    "    val, ylast = MLO_box(fh, z0, lh, uh, last_pts)\n",
    "    iteration_end_time_ML = time.time()\n",
    "    iteration_time_ML = iteration_end_time_ML - iteration_start_time_ML\n",
    "\n",
    "    iteration_times_ML.append(iteration_time_ML)\n",
    "    z0 = val.clone().detach().requires_grad_(True)\n",
    "    rel_f_err.append((norm(z0-x_torch, 'fro')/norm(z0, 'fro')).item())\n",
    "    fval = fh(z0)\n",
    "    norm_fval.append((fval/fhz).item())\n",
    "    fval.backward(retain_graph=True)\n",
    "    norm_grad.append((norm(z0.grad, 'fro')/Gz0).item())\n",
    "    z0.grad = None\n",
    "\n",
    "    print(f\"Iteration {i}: {fh(z0)} - Time: {iteration_time_ML:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 80: 15159.423940177528 - Time: 30.513409 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 81: 14913.6847847833 - Time: 30.307264 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 82: 14674.25428416332 - Time: 30.213955 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 83: 14440.914383777686 - Time: 30.401590 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 84: 14213.460516511315 - Time: 30.161213 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 85: 13991.680456978596 - Time: 30.688899 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 86: 13775.383632288898 - Time: 30.250399 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 87: 13564.385671819307 - Time: 30.143014 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 88: 13358.511991815662 - Time: 30.300542 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 89: 13157.593768544148 - Time: 30.531850 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 90: 12961.46702825332 - Time: 30.374386 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 91: 12769.966069336006 - Time: 30.504637 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction not activated\n",
      "Iteration 92: 12601.85440158091 - Time: 27.650275 seconds\n",
      "0  : coarse correction not activated\n",
      "Iteration 93: 12552.37728432114 - Time: 8.057373 seconds\n",
      "0  : coarse correction not activated\n",
      "Iteration 94: 12503.434505406132 - Time: 8.057725 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 95: 12322.19679264022 - Time: 30.237120 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction not activated\n",
      "Iteration 96: 12163.100471132046 - Time: 27.916043 seconds\n",
      "0  : coarse correction not activated\n",
      "Iteration 97: 12116.426992402987 - Time: 8.060393 seconds\n",
      "0  : coarse correction not activated\n",
      "Iteration 98: 12070.241211987139 - Time: 8.045473 seconds\n",
      "0  : coarse correction activated\n",
      "1  : coarse correction activated\n",
      "Iteration 99: 11898.53057688875 - Time: 30.290945 seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,100):\n",
    "    iteration_start_time_ML = time.time()\n",
    "    \n",
    "    val, ylast = MLO_box(fh, z0, lh, uh, last_pts)\n",
    "    iteration_end_time_ML = time.time()\n",
    "    iteration_time_ML = iteration_end_time_ML - iteration_start_time_ML\n",
    "\n",
    "    iteration_times_ML.append(iteration_time_ML)\n",
    "    z0 = val.clone().detach().requires_grad_(True)\n",
    "    rel_f_err.append((norm(z0-x_torch, 'fro')/norm(z0, 'fro')).item())\n",
    "    fval = fh(z0)\n",
    "    norm_fval.append((fval/fhz).item())\n",
    "    fval.backward(retain_graph=True)\n",
    "    norm_grad.append((norm(z0.grad, 'fro')/Gz0).item())\n",
    "    z0.grad = None\n",
    "\n",
    "    print(f\"Iteration {i}: {fh(z0)} - Time: {iteration_time_ML:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLcupy_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
