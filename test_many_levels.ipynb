{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7a507f-ca48-416e-a554-3f2bdb2bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MGTomo.model as mgmodel\n",
    "import numpy as np\n",
    "import MGTomo.tomoprojection as mgproj\n",
    "from MGTomo.utils import myexp, mylog, mydiv\n",
    "import MGTomo.functions as fcts\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import resize\n",
    "from MGTomo.optimize import armijo_linesearch\n",
    "\n",
    "from MGTomo.gridop import P,R\n",
    "\n",
    "import torch\n",
    "from torch.func import grad\n",
    "\n",
    "from torch.linalg import matrix_norm\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6b27c3-95c4-4253-828c-a8ccc8db8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_levels = 3\n",
    "maxIter = [2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e30c45d-fdef-45c3-8228-ba8e45f306bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1023\n",
    "# load image\n",
    "x_orig = shepp_logan_phantom()\n",
    "x_orig = resize(x_orig, (N,N), anti_aliasing = False)\n",
    "\n",
    "x_torch = torch.tensor(x_orig, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c76e2a-8399-4266-8245-21487f5d86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mgmodel.astra_model(N,{'mode' : 'line', 'num_angles' : 50, 'level_decrease' : 1})\n",
    "fine_dim = model.dim\n",
    "A = [mgproj.TomoTorch(model.proj_factory(fine_dim))]\n",
    "b = [A[0](x_torch)]\n",
    "level = {int(np.sqrt(A[0].shape[1])): 0}\n",
    "\n",
    "for i in range(1,max_levels+1):\n",
    "    coarse_dim = model.reduce_dim(fine_dim)\n",
    "    A.append(mgproj.TomoTorch(model.proj_factory(coarse_dim)))\n",
    "    b.append(torch.from_numpy(model.reduce_rhs(b[-1].detach().numpy(), fine_dim, coarse_dim)))\n",
    "    level.update({int(np.sqrt(A[i].shape[1])): i})\n",
    "    fine_dim=coarse_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60487db3-0ed1-4dab-b9bf-94a483d8eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c0 = A[0].sumnorm()\n",
    "#tau0 = 0.5 * 1/c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc84ce93-df57-4b12-a6fe-b1870bed64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = lambda x: fcts.kl_distance(x, A[0], b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3cd8bb-f016-4d15-97d4-ef5951ea3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = 56.0952\n",
    "tau0 = 0.5 * 1/c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe558abb-43f0-4ff2-9b5c-9a7ae8e90302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_condition(y, grad_y, kappa, y_last = None):\n",
    "    gcond = (matrix_norm(R(grad_y), ord = 1) >= kappa * matrix_norm(grad_y, ord = 1))\n",
    "    if y_last is not None:\n",
    "        y_diff_norm = matrix_norm(y_last - y, ord = 1)\n",
    "        return gcond and (y_diff_norm >= kappa)\n",
    "    else:\n",
    "        #print('y_last was none')\n",
    "        return gcond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f695cbb-70c6-456c-928b-919f0c3dd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLO(fh, y, last_pts: list, l=0, kappa = 0.5):\n",
    "    x = R(y).detach().requires_grad_(True)\n",
    "    y0, x0 = y, x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    fhy0 = fh(y0)\n",
    "    fhy0.backward(retain_graph = True)\n",
    "    grad_fhy0 = y0.grad.clone()\n",
    "    y0.grad.zero_()\n",
    "    \n",
    "    #print('coarse correction at l = ', l)\n",
    "    if coarse_condition(y, grad_fhy0, kappa, last_pts[l]):\n",
    "        #print(l, ' : coarse correction activated')\n",
    "        \n",
    "        last_pts[l] = y0.clone().detach()\n",
    "    \n",
    "        fH = lambda x: fcts.kl_distance(x, A[l+1], b[l+1])\n",
    "        fHx0 = fH(x0)\n",
    "        fHx0.backward(retain_graph = True)\n",
    "        grad_fHx0 = x0.grad.clone()\n",
    "        x0.grad.zero_()\n",
    "\n",
    "        kappa = R(grad_fhy0) - grad_fHx0\n",
    "\n",
    "        psi = lambda x: fH(x) + torch.sum(kappa * (x-x0))\n",
    "\n",
    "        for i in range(maxIter[l+1]):\n",
    "            #print(l, ': psi - ', i)\n",
    "            x.retain_grad()\n",
    "            val = fcts.SMART(psi, x, tau[l+1])\n",
    "            x = val.clone().detach().requires_grad_(True)\n",
    "            \n",
    "        if l < max_levels-1:\n",
    "            x, last_pts, _ = MLO(psi, x, last_pts, l+1)\n",
    "\n",
    "        assert psi(x) < psi(x0), 'psi(x) < psi(x0) = fH(x0) does not hold'\n",
    "    else: \n",
    "        print(l, ' : coarse correction not activated')\n",
    "    \n",
    "    d = P(x-x0)\n",
    "    z, a = armijo_linesearch(fh, y0, d)\n",
    "    \n",
    "    assert z.min() >= 0\n",
    "    \n",
    "    for i in range(maxIter[l]):\n",
    "        #print(l, ': fh - ', i)\n",
    "        z.retain_grad()\n",
    "        zval = fcts.SMART(fh, z, tau[l])\n",
    "        y0.grad.zero_()\n",
    "        z = zval.clone().detach().requires_grad_(True)\n",
    "    return z, last_pts, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0051f8e-0cda-4751-b87e-d60f09e9c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [tau0]*(max_levels+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36c062-2787-44ed-a8b0-d77e6bfc81d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9085e+08, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "0 :  tensor(286476.2362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "1 :  tensor(164373.7015, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "2 :  tensor(96462.3385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "3 :  tensor(64629.1772, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "4 :  tensor(46626.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "5 :  tensor(35377.9832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "6 :  tensor(27869.6740, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "7 :  tensor(22612.4408, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "8 :  tensor(18790.1198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "9 :  tensor(15922.7988, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "10 :  tensor(13713.8416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "11 :  tensor(11972.5598, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "12 :  tensor(10572.2615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "13 :  tensor(9426.3316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "14 :  tensor(8474.0507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "15 :  tensor(7671.8979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "16 :  tensor(6988.0587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "17 :  tensor(6588.6797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "18 :  tensor(6051.8759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "19 :  tensor(5582.3929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "20 :  tensor(5168.6022, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "21 :  tensor(4801.3848, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "22 :  tensor(4473.4999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "23 :  tensor(4179.1314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "24 :  tensor(3913.5550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "25 :  tensor(3672.8993, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "26 :  tensor(3453.9575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "27 :  tensor(3254.0506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "28 :  tensor(3070.9264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "29 :  tensor(2902.6706, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "30 :  tensor(2747.6514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "31 :  tensor(2604.4622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "32 :  tensor(2471.8917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "33 :  tensor(2348.8830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "34 :  tensor(2234.5142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "35 :  tensor(2127.9750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "36 :  tensor(2028.5532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "37 :  tensor(1935.6182, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "38 :  tensor(1848.6094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "39 :  tensor(1767.0259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "40 :  tensor(1715.5855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "41 :  tensor(1642.0675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "42 :  tensor(1572.8856, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "43 :  tensor(1507.7071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "44 :  tensor(1446.2270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "45 :  tensor(1388.1725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "46 :  tensor(1333.2953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "47 :  tensor(1281.3683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "48 :  tensor(1232.1865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "49 :  tensor(1185.5628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "50 :  tensor(1141.3237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "51 :  tensor(1099.3147, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "52 :  tensor(1059.3894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "53 :  tensor(1021.4167, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "0  : coarse correction not activated\n",
      "54 :  tensor(985.2725, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "55 :  tensor(950.8471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "0  : coarse correction not activated\n",
      "56 :  tensor(918.0342, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "z0 = torch.rand(N, N, requires_grad = True)\n",
    "last_pts = [None]*(max_levels+1)\n",
    "print(fh(z0))\n",
    "for i in range(100):\n",
    "    val, ylast, alpha = MLO(fh, z0, last_pts)\n",
    "    \n",
    "    z0 = val.clone().detach().requires_grad_(True)\n",
    "    a.append(alpha)\n",
    "    print(i, ': ', fh(z0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf13e1d-fc46-4621-bb92-64690a96935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z0.detach().numpy(), cmap = 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-MLcupy_v2]",
   "language": "python",
   "name": "conda-env-.conda-MLcupy_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
